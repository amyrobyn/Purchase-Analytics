gm1 <- glmer(clinic) ~ violence + (1 | strata), data=df)
gm1 <- glmer(clinic ~ violence + (1 | strata), data=df,family="binomial")
table(df$clinic)
gm1 <- glmer(clinic ~ violence + (1 | strata), data=df,family="Poisson")
gm1 <- glmer(clinic ~ violence + (1 | strata), data=df,link="Poisson")
gm1 <- glmer(clinic ~ violence + (1 | strata), data=df,distribution="Poisson")
gm1
summary(gm1)$coef
doTest(gm1, fixed("violence", "lr"))
gm1 <- glmer(clinic ~ violence + (1 | strata), data=df,distribution="Poisson")
gm1 <- glmer(clinic ~ violence + (1 | strata), data=df)
summary(gm1)$coef
doTest(gm1, fixed("violence", "lr"))
doTest(gm1, fixed("violence", "z"))
powerSim(gm1, fixed("violence", "z"), nsim=50)
gm1 <- glmer(clinic ~ violence + month + (1 | strata), data=df)
summary(gm1)$coef
doTest(gm1, fixed("violence", "lr"))
doTest(gm1, fixed("violence", "z"))
powerSim(gm1, fixed("violence", "z"), nsim=2)
powerSim(gm1, fixed("violence", "z"), nsim=10)
powerSim(gm1, fixed("violence", "z"), nsim=100)
gm1 <- lmer(clinic ~ violence + month + (1 | strata), data=df,family="Poisson")
summary(gm1)$coef
doTest(gm1, fixed("violence", "lr"))
doTest(gm1, fixed("violence", "z"))
powerSim(gm1, fixed("violence", "z"), nsim=50)
1/(1*4)
1/(1*4)*40
powerSim(model2, fixed("violence", "z"), nsim=50)
model1 <- makeLmer(clinic ~ violence + (1|strata), fixef=b, VarCorr=V1, sigma=s, data=df)
print(model1)
model2 <- makeGlmer(clinic ~ violence + (violence|barrio), family="poisson", fixef=b, VarCorr=V2, data=df)
print(model2)
powerSim(model1, fixed("violence", "z"), nsim=50)
read.delim("C:/Users/amykr/Downloads/CO_2015_DHS_05262019_1426_50503/COBR72FL/COBR72FL.DAT")
col<-read.delim("C:/Users/amykr/Downloads/CO_2015_DHS_05262019_1426_50503/COBR72FL/COBR72FL.DAT")
View(col)
?read.delim
col<-read.delim("C:/Users/amykr/Downloads/CO_2015_DHS_05262019_1426_50503/COBR72FL/COBR72FL.DAT", sep="")
?foreign
??foreign
col<-foreign::read.foreign("C:/Users/amykr/Downloads/CO_2015_DHS_05262019_1426_50503/COBR72FL/COBR72FL.DAT", sep="")
install.packages("sas7bdat")
require("sas7bdat")
unzip("C:/Users/amykr/Downloads/CO_2015_DHS_05262019_1426_50503/COBR72FL/COBR72FL.sas")
sas <- read.sas7bdat(file = "C:/Users/amykr/Downloads/CO_2015_DHS_05262019_1426_50503/COBR72FL/COBR72FL.sas", debug = FALSE)
sas[sas == ""] <- NA
sas <- read.sas7bdat(file = "C:/Users/amykr/Downloads/CO_2015_DHS_05262019_1426_50503/COBR72FL/COBR72FL.SAS", debug = FALSE)
read_sas("C:\Users\amykr\Downloads\CO_2015_DHS_05262019_1426_50503\COBR72FL.SAS", catalog_file = NULL, encoding = NULL,
catalog_encoding = encoding, cols_only = NULL)
read_sas("C:\Users\amykr\Downloads\CO_2015_DHS_05262019_1426_50503\COBR72FL.SAS")
read_sas("C:/Users/amykr/Downloads/CO_2015_DHS_05262019_1426_50503/COBR72FL.SAS")
haven::read_sas("C:/Users/amykr/Downloads/CO_2015_DHS_05262019_1426_50503/COBR72FL.SAS")
haven::read_sas("C:/Users/amykr/Downloads/CO_2015_DHS_05262019_1426_50503/COBR72FL/COBR72FL.SAS")
library(foreign)
dataset = read.spss("C:/Users/amykr/Downloads/CO_2015_DHS_05262019_1426_50503/COBR72FL/COBR72FL.SAS", to.data.frame=TRUE)
#alpha .05; power = .8; delta is based on 4x reduction in care seeking with increase exposure to violence;
#cluster is household with mean size of 3;  cv is variation in household size; icc is a guess with a max of .3.
#varw is within cluster variation and a guess but sapmle size is highly dependent on this.
#x2 is for 50% of households reporting fever; x4 is for 25% being due to dengue.
clusterPower::crtpwr.2rate(r1=1,r2=11,alpha=.05,power=.8,py=2,cvb=.9)*4*4
power.sim.normal(n.sim = 1000, effect.size = log(.03), alpha = .05, )
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05, )
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05)
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05,period.var = =0)
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05,period.var =0)
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05)
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05,period.effect = 0)
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05,period.effect = 0,n.periods = 48)
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05,period.effect = 0,n.periods = 48,n.clusters = 480)
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05,period.effect = 0,n.periods = 48,n.clusters = 480,cluster.size = 3)
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05,period.effect = 0,n.periods = 48,n.clusters = 480,cluster.size = 3,btw.clust.var = .01)
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05,period.effect = 0,n.periods = 48,n.clusters = 480,cluster.size = 3,btw.clust.var = .01,estimation.function = "fixed.effect.cluster.level")
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05,period.effect = 0,n.periods = 48,n.clusters = 480,cluster.size = 3,btw.clust.var = .01,estimation.function = fixed.effect.cluster.level)
clusterPower::power.sim.normal(n.sim = 1000, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05,period.effect = 0,n.periods = 48,n.clusters = 480,cluster.size = 3,btw.clust.var = .01,estimation.function = "fixed.effect.cluster.level")
clusterPower::power.sim.normal(n.sim = 10, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05,period.effect = 0,n.periods = 48,n.clusters = 480,cluster.size = 3,btw.clust.var = .01,estimation.function = "fixed.effect.cluster.level")
clusterPower::power.sim.normal(n.sim = 10, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05,period.effect = 0,n.periods = 48,n.clusters = 480,cluster.size = 3,btw.clust.var = .01, estimation.function = "fixed.effect.cluster.level")
clusterPower::power.sim.normal(n.sim = 10, effect.size = log(.25), alpha = .05,period.var =0,ICC=.05,period.effect = 0,n.periods = 48,n.clusters = 480,cluster.size = 3,btw.clust.var = .01, estimation.function = fixed.effect.cluster.level)
set.seed(17)
library(clusterPower)
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.75), alpha=.05,n.clusters = 15,n.periods = 48,
cluster.size = 5,
btw.clust.var = log(.1), period.effect = log(.45), period.var = log(0.5),
estimation.function = fixed.effect.cluster.level, ICC = log(0.1))
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.75), alpha=.05,n.clusters = 15,n.periods = 48,
cluster.size = 5,
btw.clust.var = log(.1), period.effect = log(.45), period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = log(0.1))
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.75), alpha=.05,n.clusters = 15,n.periods = 48,
cluster.size = 5,
btw.clust.var = log(.1), period.effect = log(.45), period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = log(0.1))
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.75), alpha=.05,n.clusters = 15,n.periods = 48,
cluster.size = 5,
btw.clust.var = log(.1), period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = log(0.1))
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.75), alpha=.05,n.clusters = 480,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
clusterPower::power.sim.normal(n.sim=10, effect.size=log(.75), alpha=.05,n.clusters = 480,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.75), alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.25), alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=.25, alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=.03, alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=.1, alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.25), alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.1), alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.01), alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(..001), alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.001), alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
log(.001)
log(.25)
log(.75)
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.75), alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=.03, alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=.97, alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=.25, alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.25), alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
test$power
plot(test$results)
pwr.t.test(n=25,d=0.75,sig.level=.01,alternative="greater")
library(pwr)
pwr.anova.test(k=2,f=.12,sig.level=.05,power=.8)
pwr.anova.test(k=9,f=.2,sig.level=.05,power=.8)
#To estimate minimum expected effect (log odds of 4) of violence on care seeking rates, we will survey 480
#households (~1440 persons based on three persons per household 76) in each of three neighborhoods per catchment
#area of two clinics.
#This sample size is based on a conservative estimate of four times decreased odds of accessing healthcare92 with one level increase in violence, 26% of households reporting febrile illness in the past two weeks77 (between cluster variation = 5%), and 50% of febrile illness seeking care from a health facility or provider for febrile illness77 and 24% incidence of dengue among febrile patients.78
30*2*4
#To estimate minimum expected effect (log odds of 4) of violence on care seeking rates, we will survey 480
#households (~1440 persons based on three persons per household 76) in each of three neighborhoods per catchment
#area of two clinics.
#This sample size is based on a conservative estimate of four times decreased odds of accessing healthcare92 with one level increase in violence, 26% of households reporting febrile illness in the past two weeks77 (between cluster variation = 5%), and 50% of febrile illness seeking care from a health facility or provider for febrile illness77 and 24% incidence of dengue among febrile patients.78
30*2*4*2
pwr.t.test(d=0.10,sig.level=.05,power=.8)
pwr.t.test(n = NULL, d = 0.25, sig.level = 0.05, power = .8, type = c("paired"), alternative = c("two.sided"))
pwr.t.test(n = NULL, d = 0.1, sig.level = 0.05, power = .8, type = c("paired"), alternative = c("two.sided"))
pwr.t.test(n = NULL, d = 0.1, sig.level = 0.05, power = .8, alternative = c("two.sided"))
pwr.anova.test(k=2,f=.12,sig.level=.05,power=.8)
#alpha .05; power = .8; delta is based on 97% reduction in acute testing with increase exposure to homocides;
#cluster is household with mean size of 3;  cv is variation in household size; icc is a guess with a max of .3.
#varw is within cluster variation and a guess but sapmle size is highly dependent on this.
#x2 is for 50% of households reporting fever; x4 is for 25% being due to dengue.
clusterPower::crtpwr.2mean(alpha = .05, power = 0.8, cv=2, d=0.97, icc=.3,varw=.01,n=3)*2*4
#alpha .05; power = .8; delta is based on 97% reduction in acute testing with increase exposure to homocides;
#cluster is household with mean size of 3;  cv is variation in household size; icc is a guess.
#varw is within cluster variation and a guess but sapmle size is highly dependent on this.
#x2 is for 50% of households reporting fever; x4 is for 25% being due to dengue.
clusterPower::crtpwr.2prop(n=3,cv=5,icc=.5,alpha=.05,power=.8,p1=1,p2=0.03)*2*4
#alpha .05; power = .8; delta is based on 4x reduction in care seeking with increase exposure to violence;
#cluster is household with mean size of 3;  cv is variation in household size; icc is a guess with a max of .3.
#varw is within cluster variation and a guess but sapmle size is highly dependent on this.
#x2 is for 25% of households reporting fever; x4 is for 25% being due to dengue.
clusterPower::crtpwr.2rate(r1=1,r2=11,alpha=.05,power=.8,py=2,cvb=.9)*4*4
test<-clusterPower::power.sim.normal(n.sim=10, effect.size=log(.25), alpha=.05,n.clusters = 30,n.periods = 48,
cluster.size = 3,
btw.clust.var = .1, period.effect = 0, period.var = 0.5,
estimation.function = fixed.effect.cluster.level, ICC = 0.1)
test$power
#alpha .05; power = .8; delta is based on 97% reduction in acute testing with increase exposure to homocides;
#cluster is household with mean size of 3;  cv is variation in household size; icc is a guess with a max of .3.
#varw is within cluster variation and a guess but sapmle size is highly dependent on this.
#x2 is for 50% of households reporting fever; x4 is for 25% being due to dengue.
clusterPower::crtpwr.2mean(alpha = .05, power = 0.8, cv=2, d=0.97, icc=.3,varw=.01,n=3)*2*4
clusterPower::crtpwr.2mean(alpha = .05, power = 0.8, cv=2, d=0.1, icc=.3,varw=.01,n=3)*2*4
clusterPower::crtpwr.2mean(alpha = .05, power = 0.8, cv=2, d=0.1, icc=.3,varw=.01,n=3)
# aim 1 -------------------------------------------------------------------
#219 acute febrile patients will be enrolled for a single study visit over an enrollment period of two years from two clinics (total n = 438). This sample size calculation (Cohens D) is based on 6% of dengue cases currently reported under traditional surveillance system,29,30 a 10% expected increase in reporting in FeverDX clinic vs control clinics with 80% power, and 95% confidence.
pwr.t.test(n = NULL, d = 0.1, sig.level = 0.05, power = .8, type = c("paired"), alternative = c("two.sided"))
# aim 1 -------------------------------------------------------------------
#219 acute febrile patients will be enrolled for a single study visit over an enrollment period of two years from two clinics (total n = 438). This sample size calculation (Cohens D) is based on 6% of dengue cases currently reported under traditional surveillance system,29,30 a 10% expected increase in reporting in FeverDX clinic vs control clinics with 80% power, and 95% confidence.
pwr.t.test(n = NULL, d = 0.1, sig.level = 0.05, power = .8, alternative = c("two.sided"))
, type = c("paired")
# aim 1 -------------------------------------------------------------------
#219 acute febrile patients will be enrolled for a single study visit over an enrollment period of two years from two clinics (total n = 438). This sample size calculation (Cohens D) is based on 6% of dengue cases currently reported under traditional surveillance system,29,30 a 10% expected increase in reporting in FeverDX clinic vs control clinics with 80% power, and 95% confidence.
pwr.t.test(n = NULL, d = 0.1, sig.level = 0.05, power = .8, type = c("paired"), alternative = c("two.sided"))
# aim 1 -------------------------------------------------------------------
#219 acute febrile patients will be enrolled for a single study visit over an enrollment period of two years from two clinics (total n = 438). This sample size calculation (Cohens D) is based on 6% of dengue cases currently reported under traditional surveillance system,29,30 a 10% expected increase in reporting in FeverDX clinic vs control clinics with 80% power, and 95% confidence.
pwr.t.test(n = NULL, d = 0.2, sig.level = 0.05, power = .8, type = c("paired"), alternative = c("two.sided"))
pwr.anova.test(k=6,f=.2,sig.level=.05,power=.8)
library(pwr)
pwr.anova.test(k=6,f=.2,sig.level=.05,power=.8)
55*6
330*24
7920*.2
1584/2
$1,238/7920
1238/7920
7920*.16
7920*.15
1188/2
pwr.anova.test(k=2,f=.2,sig.level=.05,power=.8)
library(pwr)
pwr.anova.test(k=2,f=.2,sig.level=.05,power=.8)
pwr.anova.test(k=2,f=.3,sig.level=.05,power=.8)
pwr.anova.test(k=2,f=.31,sig.level=.05,power=.8)
pwr.anova.test(k=2,f=.3,sig.level=.05,power=.8)
44*2*24
require(R2BayesX)
?R2BayesX
setwd("C:/Users/amykr/Documents/GitHub/Purchase-Analytics")
products<-read.csv(file = "input/products.csv")
products<-read.csv(file = "input/products.csv")
order_products<-read.csv(file = "input/order_products.csv")
View(products)
View(order_products)
merge<-merge(products,order_products,by="product_id")
report<-merge
write.csv(report,"report.csv")
View(merge)
?mutate
library(plyr)
?mutate
merge%>%group_by(department_id)%>%mutate(orders = sum(product_id))
merge%>%
group_by(department_id)%>%
mutate(orders = sum(product_id))
library(dplyr)
merge%>%
group_by(department_id)%>%
mutate(orders = sum(product_id))
merge%>%
group_by(department_id)%>%
mutate(orders = count(product_id))
merge%>%
group_by(factor(department_id))%>%
mutate(orders = count(product_id))
class(merge$department_id)
merge$department_id<-as.factor(merge$department_id)
class(merge$department_id)
merge%>%
group_by(factor(department_id))%>%
mutate(orders = count(product_id))
merge%>%
group_by(factor(department_id))%>%
mutate(orders = sum(product_id))
?count
library(plyr)
merge%>%
group_by(factor(department_id))%>%
mutate(orders = sum(product_id))
merge%>%
group_by(factor(department_id))%>%
mutate(orders = count(product_id))
merge%>%
group_by(factor(department_id))%>%
mutate(count(product_id,"orders"))
merge%>%
group_by(factor(department_id))%>%
mutate(orders = sum(product_id))
merge%>%
group_by(factor(department_id))%>%
mutate(orders = _n(product_id))
merge%>%
group_by(factor(department_id))%>%
mutate(orders = _n(product_id))
merge%>%
group_by(factor(department_id,product_id))%>%
mutate(orders = n())
merge %>% add_count(department_id,product_id)
merge %>% add_count(department_id,product_id,reordered)
merge<-merge %>% add_count(department_id,product_id)
merge %>% add_count(department_id,product_id,reordered)
merge<-merge %>% add_count(department_id,product_id)
merge
merge %>% add_count(department_id,product_id,reordered)
report<-merge(products,order_products,by="product_id")
report<-report %>% add_count(department_id,product_id)
report %>% add_count(department_id,product_id,reordered)
write.csv(report,"report.csv")
setwd("C:/Users/amykr/Documents/GitHub/Purchase-Analytics")
products<-read.csv(file = "input/products.csv")
order_products<-read.csv(file = "input/order_products.csv")
report<-merge(products,order_products,by="product_id")
library(dplyr)
report<-report %>% add_count(department_id,product_id)
report %>% add_count(department_id,product_id,reordered)
write.csv(report,"report.csv")
write.csv(report,file="report.csv")
report$ratio<-report$reordered/report$n
write.csv(report,file="report.csv")
report
write.csv(report,file="C:/Users/amykr/Documents/GitHub/Purchase-Analytics/output/report.csv")
report<-report %>% add_count(department_id)
report<-merge(products,order_products,by="product_id")
library(dplyr)
report<-report %>% add_count(department_id)
report %>% add_count(department_id,reordered)
report$ratio<-report$reordered/report$n
write.csv(report,file="C:/Users/amykr/Documents/GitHub/Purchase-Analytics/output/report.csv")
report %>% mutate(reordered_count=sum(reordered))
report<-report %>% add_count(department_id)
report %>% add_count(department_id,reordered)
report<-merge(products,order_products,by="product_id")
library(dplyr)
report<-report %>% add_count(department_id)
report %>% add_count(department_id,reordered)
report %>% mutate(reordered_count=sum(reordered))
report<-merge(products,order_products,by="product_id")
library(dplyr)
report<-report %>% add_count(department_id)
report
report<-report %>% by_group(department_id)>%>mutate(number_of_first_orders=sum(reordered==0))
report<-report %>%
by_group(department_id)%>%
mutate(number_of_first_orders=sum(reordered==0))
report<-report %>%
group_by(department_id)%>%
mutate(number_of_first_orders=sum(reordered==0))
report
report %>% add_count(department_id,reordered)
report
?melt
??melt
library(reshape)
?melt
test<-melt(report,id.vars = department_id,measure.vars = reordered)
test<-melt(report,id.vars = "department_id",measure.vars = "reordered")
View(test)
setkey(report,department_id)
report %>%
group_by(department_id) %>%
summarise(number_of_orders=count(department_id))
report %>%
add_count(department_id)
report<-merge(products,order_products,by="product_id")
library(dplyr)
library(reshape)
report %>%
add_count(department_id)
report %>%
count(department_id, sort = TRUE, name = "n_species")
report %>%
count(department_id, sort = TRUE, name = "number_of_orders")%>%
count(reordered, sort = TRUE, name = "number_of_first_orders")%>%
report %>%
add_count(department_id)
report%>%
count(reordered, sort = TRUE, name = "number_of_first_orders")%>%
report %>%
add_count(department_id)
report%>%
count(department_id, sort = TRUE, name = "number_of_first_orders")%>%
report%>%
count(reordered, sort = TRUE, name = "number_of_first_orders")%>%
report %>%
add_count(department_id)
report%>%
count(department_id, sort = TRUE, name = "number_of_first_orders")
report%>%
count(reordered, sort = TRUE, name = "number_of_first_orders")%>%
%>%
filter(n == 1)
report%>%
count(reordered, sort = TRUE, name = "number_of_first_orders")
report%>%
count(department_id,reordered, sort = TRUE, name = "number_of_first_orders")
report %>% add_count(department_id)
mtcars %>% group_by(department_id) %>% count(reordered)
report %>% group_by(department_id) %>% count(reordered)
report %>% group_by(department_id) %>% tally()
report %>%
count(department_id, sort = TRUE, name = "number_of_orders")
report%>%
count(department_id, sort = TRUE, name = "number_of_first_orders")
report%>%
count(department_id,reordered, sort = TRUE, name = "number_of_first_orders")%>%
filter(reordered == 0)
report%>%
tally(department_id,reordered, sort = TRUE, name = "number_of_first_orders")%>%
filter(reordered == 0)
report%>%
count(department_id, sort = TRUE, name = "number_of_first_orders")%>%
filter(reordered == 0)
report %>% group_by(department_id) %>% tally()
report %>%count(department_id, sort = TRUE, name = "number_of_orders")
merge<-merge(products,order_products,by="product_id")
report<-merge %>%count(department_id, sort = TRUE, name = "number_of_orders")
report
merge %>%group_by(department_id)%>%count(reorder==0, sort = TRUE, name = "number_of_orders")
merge %>%group_by(department_id)%>%count(reorder==0)
class(merge$reordered)
merge %>%group_by(department_id)%>%count(reordered==0)
merge %>%group_by(department_id)%>%sum(reordered==0)
merge %>%group_by(department_id)%>%sum(reordered==0)
merge %>%group_by(department_id)%>%count(reordered==0)
merge %>%group_by(department_id)%>%count(reordered==0)%>%filter(reordered==0)
merge %>%group_by(department_id)%>%filter(reordered==0)
merge %>%group_by(department_id)%>%filter(reordered==0)%>%count(department_id, sort = TRUE, name = "number_of_orders")
merge %>%group_by(department_id)%>%filter(reordered==0)%>%count(department_id, sort = TRUE, name = "number_of_first_orders")
report<-merge %>%group_by(department_id)%>%filter(reordered==0)%>%count(department_id, sort = TRUE, name = "number_of_first_orders")
report
merge(report1,report2,by="department_id")
report1<-merge%>%count(department_id, sort = TRUE, name = "number_of_orders")
report2<-merge%>%group_by(department_id)%>%filter(reordered==0)%>%count(department_id, sort = TRUE, name = "number_of_first_orders")
merge(report1,report2,by="department_id")
merge(report1,report2,by="department_id",all=T)
report %>%
group_by(department_id) %>%
summarise(number_of_orders=count(department_id))
merge %>%
group_by(department_id) %>%
summarise(number_of_orders=count(department_id))
merge
merge %>%
group_by(department_id) %>%
summarise(number_of_orders=sum(department_id))
merge %>%
group_by(department_id) %>%
summarise(number_of_orders=sum(reordered))
merge %>%
group_by(department_id) %>%
summarise(number_of_first_orders=sum(reordered==0))
merge %>%
group_by(department_id) %>%
summarise(number_of_orders=count(department_id),number_of_first_orders=sum(reordered==0))
?summarise
merge %>%
group_by(department_id) %>%
summarise(number_of_orders=length(unique(department_id)),number_of_first_orders=sum(reordered==0))
merge %>%
group_by(department_id) %>%
summarise(number_of_orders=length((department_id)),number_of_first_orders=sum(reordered==0))
merge %>%
group_by(department_id) %>%
summarise(number_of_orders=length((department_id)),number_of_first_orders=sum(reordered==0))
merge %>%
group_by(department_id) %>%
summarise(number_of_orders=length((department_id)),number_of_first_orders=sum(reordered==0),percentage=number_of_first_orders/number_of_orders)
setwd("C:/Users/amykr/Documents/GitHub/Purchase-Analytics")
products<-read.csv(file = "input/products.csv")
order_products<-read.csv(file = "input/order_products.csv")
merge<-merge(products,order_products,by="product_id")
report<-merge %>%
group_by(department_id) %>%
summarise(number_of_orders=length((department_id)),number_of_first_orders=sum(reordered==0),percentage=number_of_first_orders/number_of_orders)
write.csv(report,file="C:/Users/amykr/Documents/GitHub/Purchase-Analytics/output/report.csv")
setwd("C:/Users/amykr/Documents/GitHub/Purchase-Analytics")
products<-read.csv(file = "input/products.csv")
order_products<-read.csv(file = "input/order_products.csv")
merge<-merge(products,order_products,by="product_id")
report<-merge %>%
group_by(department_id) %>%
summarise(number_of_orders=length((department_id)),number_of_first_orders=sum(reordered==0),percentage=number_of_first_orders/number_of_orders)
write.csv(report,file="C:/Users/amykr/Documents/GitHub/Purchase-Analytics/output/report.csv")
